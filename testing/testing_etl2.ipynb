{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebpage_url = 'https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component={}&CycleBeginYear={}'\n",
    "data_attributes_file_path = \"data_attributes.json\"\n",
    "file_directories_file_path = 'file_directories.json'\n",
    "\n",
    "start_years = [1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013, 2015]\n",
    "output_directory = 'data_test'\n",
    "\n",
    "attribute_name_map_file_path = 'data_attribute_names_map.json'\n",
    "\n",
    "with open(attribute_name_map_file_path, \"r\") as file:\n",
    "        attribute_name_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_attributes(directory, year_range):\n",
    "    with open(attribute_name_map_file_path, \"r\") as file:\n",
    "        attribute_name_map = json.load(file)\n",
    "\n",
    "    result_df = pd.DataFrame({'SEQN': []})\n",
    "    for file_name in os.listdir(directory):\n",
    "        data_file_path = os.path.join(directory, file_name)\n",
    "        file_df = pd.read_sas(data_file_path, format='xport')\n",
    "        \n",
    "        # if 'SEQN' in file_df.columns:\n",
    "        #     print('SEQN FOUND')\n",
    "\n",
    "        \n",
    "        extracted_columns = file_df.columns.intersection(attribute_name_map.keys())\n",
    "        extracted_columns = list(extracted_columns) + ['SEQN']\n",
    "        print(f'Length of dataset extracted from {file_name}: ', len(file_df))\n",
    "        df_i = file_df[extracted_columns]\n",
    "        df_i = df_i.rename(columns=attribute_name_map)\n",
    "\n",
    "        result_df = result_df.merge(df_i, how='outer', on='SEQN')\n",
    "\n",
    "    print('Length of resulting DF:', len(result_df))\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~EXTRACTING 1999-2000 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BMX.xpt:  9282\n",
      "Length of dataset extracted from BPX.xpt:  9282\n",
      "Length of dataset extracted from DEMO.xpt:  9965\n",
      "Length of dataset extracted from DIQ.xpt:  9493\n",
      "Length of dataset extracted from LAB10.xpt:  6758\n",
      "Length of dataset extracted from LAB13.xpt:  8344\n",
      "Length of dataset extracted from LAB18.xpt:  6758\n",
      "Length of dataset extracted from LAB25.xpt:  8832\n",
      "Length of dataset extracted from MCQ.xpt:  9493\n",
      "Length of dataset extracted from PAQ.xpt:  9188\n",
      "Length of resulting DF: 9965\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2001-2002 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BMX_B.xpt:  10477\n",
      "Length of dataset extracted from BPX_B.xpt:  10477\n",
      "Length of dataset extracted from DEMO_B.xpt:  11039\n",
      "Length of dataset extracted from DIQ_B.xpt:  10470\n",
      "Length of dataset extracted from L10_2_B.xpt:  557\n",
      "Length of dataset extracted from L10_B.xpt:  7445\n",
      "Length of dataset extracted from L13_B.xpt:  9262\n",
      "Length of dataset extracted from L25_B.xpt:  9929\n",
      "Length of dataset extracted from L40_2_B.xpt:  546\n",
      "Length of dataset extracted from L40_B.xpt:  7445\n",
      "Length of dataset extracted from MCQ_B.xpt:  10470\n",
      "Length of dataset extracted from PAQ_B.xpt:  10094\n",
      "Length of resulting DF: 11039\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2003-2004 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BMX_C.xpt:  9643\n",
      "Length of dataset extracted from BPX_C.xpt:  9643\n",
      "Length of dataset extracted from DEMO_C.xpt:  10122\n",
      "Length of dataset extracted from DIQ_C.xpt:  9645\n",
      "Length of dataset extracted from L10_C.xpt:  6990\n",
      "Length of dataset extracted from L13_C.xpt:  8556\n",
      "Length of dataset extracted from L25_C.xpt:  9179\n",
      "Length of dataset extracted from L40_C.xpt:  6990\n",
      "Length of dataset extracted from MCQ_C.xpt:  9645\n",
      "Length of dataset extracted from PAQ_C.xpt:  9278\n",
      "Length of resulting DF: 10122\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2005-2006 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BIOPRO_D.xpt:  6980\n",
      "Length of dataset extracted from BMX_D.xpt:  9950\n",
      "Length of dataset extracted from BPX_D.xpt:  9950\n",
      "Length of dataset extracted from CBC_D.xpt:  9440\n",
      "Length of dataset extracted from DEMO_D.xpt:  10348\n",
      "Length of dataset extracted from DIQ_D.xpt:  9822\n",
      "Length of dataset extracted from GHB_D.xpt:  6980\n",
      "Length of dataset extracted from HDL_D.xpt:  8086\n",
      "Length of dataset extracted from MCQ_D.xpt:  9822\n",
      "Length of dataset extracted from PAQ_D.xpt:  9424\n",
      "Length of dataset extracted from TCHOL_D.xpt:  8086\n",
      "Length of resulting DF: 10348\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2007-2008 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BIOPRO_E.xpt:  6917\n",
      "Length of dataset extracted from BMX_E.xpt:  9762\n",
      "Length of dataset extracted from BPX_E.xpt:  9762\n",
      "Length of dataset extracted from CBC_E.xpt:  9307\n",
      "Length of dataset extracted from DEMO_E.xpt:  10149\n",
      "Length of dataset extracted from DIQ_E.xpt:  9666\n",
      "Length of dataset extracted from GHB_E.xpt:  6917\n",
      "Length of dataset extracted from HDL_E.xpt:  8132\n",
      "Length of dataset extracted from MCQ_E.xpt:  9666\n",
      "Length of dataset extracted from PAQ_E.xpt:  9359\n",
      "Length of dataset extracted from TCHOL_E.xpt:  8132\n",
      "Length of resulting DF: 10149\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2009-2010 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BIOPRO_F.xpt:  7369\n",
      "Length of dataset extracted from BMX_F.xpt:  10253\n",
      "Length of dataset extracted from BPX_F.xpt:  10253\n",
      "Length of dataset extracted from CBC_F.xpt:  9835\n",
      "Length of dataset extracted from DEMO_F.xpt:  10537\n",
      "Length of dataset extracted from DIQ_F.xpt:  10109\n",
      "Length of dataset extracted from GHB_F.xpt:  7369\n",
      "Length of dataset extracted from HDL_F.xpt:  8591\n",
      "Length of dataset extracted from MCQ_F.xpt:  10109\n",
      "Length of dataset extracted from PAQ_F.xpt:  9771\n",
      "Length of dataset extracted from TCHOL_F.xpt:  8591\n",
      "Length of resulting DF: 10537\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2011-2012 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BIOPRO_G.xpt:  6549\n",
      "Length of dataset extracted from BMX_G.xpt:  9338\n",
      "Length of dataset extracted from BPX_G.xpt:  9338\n",
      "Length of dataset extracted from CBC_G.xpt:  8956\n",
      "Length of dataset extracted from DEMO_G.xpt:  9756\n",
      "Length of dataset extracted from DIQ_G.xpt:  9364\n",
      "Length of dataset extracted from GHB_G.xpt:  6549\n",
      "Length of dataset extracted from HDL_G.xpt:  7821\n",
      "Length of dataset extracted from MCQ_G.xpt:  9364\n",
      "Length of dataset extracted from PAQ_G.xpt:  9107\n",
      "Length of dataset extracted from TCHOL_G.xpt:  7821\n",
      "Length of resulting DF: 9756\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2013-2014 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BIOPRO_H.xpt:  6979\n",
      "Length of dataset extracted from BMX_H.xpt:  9813\n",
      "Length of dataset extracted from BPX_H.xpt:  9813\n",
      "Length of dataset extracted from CBC_H.xpt:  9422\n",
      "Length of dataset extracted from DEMO_H.xpt:  10175\n",
      "Length of dataset extracted from DIQ_H.xpt:  9770\n",
      "Length of dataset extracted from GHB_H.xpt:  6979\n",
      "Length of dataset extracted from HDL_H.xpt:  8291\n",
      "Length of dataset extracted from MCQ_H.xpt:  9770\n",
      "Length of dataset extracted from PAQ_H.xpt:  9484\n",
      "Length of dataset extracted from TCHOL_H.xpt:  8291\n",
      "Length of resulting DF: 10175\n",
      "~~~~DONE.~~~~\n",
      "\n",
      "~~~~EXTRACTING 2015-2016 DATA~~~~\n",
      "\n",
      "Length of dataset extracted from BIOPRO_I.xpt:  6744\n",
      "Length of dataset extracted from BMX_I.xpt:  9544\n",
      "Length of dataset extracted from BPX_I.xpt:  9544\n",
      "Length of dataset extracted from CBC_I.xpt:  9165\n",
      "Length of dataset extracted from DEMO_I.xpt:  9971\n",
      "Length of dataset extracted from DIQ_I.xpt:  9575\n",
      "Length of dataset extracted from GHB_I.xpt:  6744\n",
      "Length of dataset extracted from HDL_I.xpt:  8021\n",
      "Length of dataset extracted from MCQ_I.xpt:  9575\n",
      "Length of dataset extracted from PAQ_I.xpt:  9255\n",
      "Length of dataset extracted from TCHOL_I.xpt:  8021\n",
      "Length of resulting DF: 9971\n",
      "~~~~DONE.~~~~\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Systolic</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Glycohemoglobin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean volume of platelets</th>\n",
       "      <th>Coronary heart disease</th>\n",
       "      <th>Blood related diabetes</th>\n",
       "      <th>Blood related stroke</th>\n",
       "      <th>Moderate-work</th>\n",
       "      <th>Vigorous-work</th>\n",
       "      <th>Glycohemoglobin_x</th>\n",
       "      <th>Glycohemoglobin_y</th>\n",
       "      <th>Glucose_x</th>\n",
       "      <th>Glucose_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.90</td>\n",
       "      <td>106.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.56</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.63</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.10</td>\n",
       "      <td>122.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>93698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>93699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.71</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>93700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.72</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>93701.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.10</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>93702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.40</td>\n",
       "      <td>118.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.14</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92062 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN  Weight  Body mass index  Systolic  Diastolic  Gender    Age  \\\n",
       "0         1.0     3.0            14.90       NaN        NaN     2.0   29.0   \n",
       "1         2.0     NaN            24.90     106.0       58.0     1.0  926.0   \n",
       "2         3.0     NaN            17.63     110.0       60.0     2.0  125.0   \n",
       "3         4.0     NaN              NaN       NaN        NaN     1.0   22.0   \n",
       "4         5.0     NaN            29.10     122.0       82.0     1.0  597.0   \n",
       "...       ...     ...              ...       ...        ...     ...    ...   \n",
       "9966  93698.0     NaN              NaN       NaN        NaN     1.0    NaN   \n",
       "9967  93699.0     NaN            18.20       NaN        NaN     2.0    NaN   \n",
       "9968  93700.0     NaN            26.00     104.0       62.0     1.0    NaN   \n",
       "9969  93701.0     NaN            18.10     114.0       48.0     1.0    NaN   \n",
       "9970  93702.0     NaN            21.40     118.0       66.0     2.0    NaN   \n",
       "\n",
       "      Diabetes  Glycohemoglobin  Cholesterol  ...  Mean volume of platelets  \\\n",
       "0          2.0              NaN          NaN  ...                       NaN   \n",
       "1          2.0              4.7         5.56  ...                       7.7   \n",
       "2          2.0              NaN         3.34  ...                       8.6   \n",
       "3          2.0              NaN          NaN  ...                       7.8   \n",
       "4          2.0              5.5         7.21  ...                      10.4   \n",
       "...        ...              ...          ...  ...                       ...   \n",
       "9966       2.0              NaN          NaN  ...                       7.0   \n",
       "9967       2.0              NaN         4.71  ...                       7.3   \n",
       "9968       2.0              5.2         3.72  ...                       9.6   \n",
       "9969       2.0              NaN         5.09  ...                       7.8   \n",
       "9970       2.0              4.6         4.14  ...                       8.7   \n",
       "\n",
       "      Coronary heart disease  Blood related diabetes  Blood related stroke  \\\n",
       "0                        NaN                     NaN                   NaN   \n",
       "1                        2.0                     2.0                   2.0   \n",
       "2                        NaN                     NaN                   NaN   \n",
       "3                        NaN                     NaN                   NaN   \n",
       "4                        2.0                     2.0                   2.0   \n",
       "...                      ...                     ...                   ...   \n",
       "9966                     NaN                     NaN                   NaN   \n",
       "9967                     NaN                     NaN                   NaN   \n",
       "9968                     2.0                     2.0                   NaN   \n",
       "9969                     NaN                     NaN                   NaN   \n",
       "9970                     2.0                     2.0                   NaN   \n",
       "\n",
       "      Moderate-work  Vigorous-work  Glycohemoglobin_x  Glycohemoglobin_y  \\\n",
       "0               NaN            NaN                NaN                NaN   \n",
       "1               NaN            3.0                NaN                NaN   \n",
       "2               NaN            NaN                NaN                NaN   \n",
       "3               NaN            NaN                NaN                NaN   \n",
       "4              17.0            1.0                NaN                NaN   \n",
       "...             ...            ...                ...                ...   \n",
       "9966            NaN            NaN                NaN                NaN   \n",
       "9967            NaN            NaN                NaN                NaN   \n",
       "9968            2.0            2.0                NaN                NaN   \n",
       "9969            NaN            NaN                NaN                NaN   \n",
       "9970            2.0            2.0                NaN                NaN   \n",
       "\n",
       "      Glucose_x  Glucose_y  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "9966        NaN        NaN  \n",
       "9967        NaN        NaN  \n",
       "9968        NaN        NaN  \n",
       "9969        NaN        NaN  \n",
       "9970        NaN        NaN  \n",
       "\n",
       "[92062 rows x 41 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for start_year in start_years:\n",
    "    year_range = str(start_year) + '-' + str(start_year + 1)\n",
    "    print(f'~~~~EXTRACTING {year_range} DATA~~~~')\n",
    "\n",
    "    output_file_path = f'{output_directory}/{year_range}'\n",
    "    print()\n",
    "\n",
    "    # extract all of the desired attributes into the same dataframe\n",
    "    dfs.append(process_attributes(output_file_path, year_range))\n",
    "\n",
    "    # break\n",
    "    print(f'~~~~DONE.~~~~\\n')\n",
    "\n",
    "pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
