{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score,accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "import time\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Systolic</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Glycohemoglobin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>High-density lipoprotein (HDL)</th>\n",
       "      <th>...</th>\n",
       "      <th>Basophils</th>\n",
       "      <th>Red blood cells</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Red blood cell width</th>\n",
       "      <th>Platelet count</th>\n",
       "      <th>Mean volume of platelets</th>\n",
       "      <th>Coronary heart disease</th>\n",
       "      <th>Blood related diabetes</th>\n",
       "      <th>Moderate-work</th>\n",
       "      <th>Vigorous-work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.5</td>\n",
       "      <td>29.10</td>\n",
       "      <td>122.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>597.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.21</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.13</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>209.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.0</td>\n",
       "      <td>29.39</td>\n",
       "      <td>130.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>712.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.34</td>\n",
       "      <td>2.73</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>4.60</td>\n",
       "      <td>13.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>244.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111.8</td>\n",
       "      <td>30.94</td>\n",
       "      <td>152.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>518.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.31</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.00</td>\n",
       "      <td>15.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>167.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>No</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Don't know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>75.5</td>\n",
       "      <td>27.33</td>\n",
       "      <td>142.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>973.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>5.32</td>\n",
       "      <td>16.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.6</td>\n",
       "      <td>26.68</td>\n",
       "      <td>106.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>459.0</td>\n",
       "      <td>No</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.15</td>\n",
       "      <td>1.49</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>4.14</td>\n",
       "      <td>13.3</td>\n",
       "      <td>11.9</td>\n",
       "      <td>255.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weight  Body mass index  Systolic  Diastolic  Gender    Age Diabetes  \\\n",
       "4     92.5            29.10     122.0       82.0    Male  597.0       No   \n",
       "6     78.0            29.39     130.0       78.0  Female  712.0       No   \n",
       "9    111.8            30.94     152.0       98.0    Male  518.0       No   \n",
       "13    75.5            27.33     142.0       56.0    Male  973.0       No   \n",
       "14    81.6            26.68     106.0       68.0  Female  459.0       No   \n",
       "\n",
       "    Glycohemoglobin  Cholesterol  High-density lipoprotein (HDL)  ...  \\\n",
       "4               5.5         7.21                            1.08  ...   \n",
       "6               5.8         6.34                            2.73  ...   \n",
       "9               5.5         3.62                            1.31  ...   \n",
       "13              5.8         4.50                            1.04  ...   \n",
       "14              4.6         5.15                            1.49  ...   \n",
       "\n",
       "       Basophils  Red blood cells  Hemoglobin  Red blood cell width  \\\n",
       "4   5.397605e-79             5.13        14.5                  13.1   \n",
       "6   5.397605e-79             4.60        13.4                  14.3   \n",
       "9   5.397605e-79             5.00        15.4                  13.7   \n",
       "13  5.397605e-79             5.32        16.6                  12.4   \n",
       "14  5.397605e-79             4.14        13.3                  11.9   \n",
       "\n",
       "    Platelet count  Mean volume of platelets  Coronary heart disease  \\\n",
       "4            209.0                      10.4                      No   \n",
       "6            244.0                       8.2                      No   \n",
       "9            167.0                       9.4                      No   \n",
       "13           160.0                       9.0                      No   \n",
       "14           255.0                       7.7                      No   \n",
       "\n",
       "    Blood related diabetes  Moderate-work  Vigorous-work  \n",
       "4                       No           17.0            Yes  \n",
       "6                      Yes            3.0             No  \n",
       "9               Don't know           13.0     Don't know  \n",
       "13                      No            9.0            Yes  \n",
       "14                      No           13.0            Yes  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/nhanes_data_processed.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_load_data(data = pd.DataFrame, target = str):\n",
    "    #The input should only be a Pandas DataFrame \n",
    " \n",
    "    #This creates split datasets for training, testing, and validation\n",
    "    #Additionally it prepares the input data sets for model fitting and predicting\n",
    "    X = data.drop(target, axis = 1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_val =  scaler.transform(X_val)\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Model - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows and columns\n",
    "num_rows = 1000\n",
    "num_columns = 41\n",
    "\n",
    "# Generate random float data for 39 columns\n",
    "float_data = np.random.rand(num_rows, num_columns - 2)\n",
    "\n",
    "# Generate two binary columns\n",
    "binary_data = np.random.randint(0, 2, size=(num_rows, 2))\n",
    "\n",
    "# Combine into a single dataset\n",
    "data = np.hstack((float_data, binary_data))\n",
    "\n",
    "# Create column names\n",
    "column_names = [f\"feature_{i}\" for i in range(1, num_columns - 1)]\n",
    "column_names.append(\"Gender\")\n",
    "column_names.append(\"CHD\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHD'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df.columns[:-1]  # All columns except the last two (includes sensitive feature)\n",
    "sensitive_column = df.columns[-2]  # The third last column as the sensitive feature\n",
    "label_columns = df.columns[-1]  # The last two columns as labels\n",
    "\n",
    "# Convert Pandas DataFrame to a TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    df[feature_columns].values.astype(np.float32),  # Features\n",
    "    df[sensitive_column].values.reshape(-1, 1).astype(np.int32),  # Sensitive Feature\n",
    "    df[label_columns].values.astype(np.int32)  # Ensure labels are integers\n",
    "))\n",
    "# Define batch size\n",
    "batch_size = 16  \n",
    "\n",
    "# Shuffle before batching\n",
    "buffer_size = len(df)  # Ideally, use the dataset size as the buffer\n",
    "shuffled_dataset = dataset.shuffle(buffer_size, seed=42).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape: (16, 40)\n",
      "Sensitive Feature batch shape: (16, 1)\n",
      "Labels batch shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "for batch in shuffled_dataset.take(1):  \n",
    "    features, sensitive_features, labels = batch\n",
    "    print(\"Features batch shape:\", features.shape)  \n",
    "    print(\"Sensitive Feature batch shape:\", sensitive_features.shape)  \n",
    "    print(\"Labels batch shape:\", labels.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 unique labels: [1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1]\n",
      "Batch 1 unique labels: [0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1]\n",
      "Batch 2 unique labels: [1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1]\n",
      "Batch 3 unique labels: [0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0]\n",
      "Batch 4 unique labels: [0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "for step, (x, z, labels) in enumerate(shuffled_dataset.take(5)):  # Check first 5 batches\n",
    "    unique_labels = np.unique(labels.numpy())\n",
    "    print(f\"Batch {step} unique labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialModel(keras.Model):\n",
    "    def __init__(self, input_dim, sensitive_attr,lambda_tradeoff=0.1, GBT_retrain = 5, epochs = 100):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize Attributes\n",
    "        self.lambda_tradeoff = lambda_tradeoff  # Trade-off parameter for adversarial penalty\n",
    "        self.sensitive_attr = sensitive_attr\n",
    "        self.epochs = epochs\n",
    "        self.GBT_retrain = GBT_retrain\n",
    "   \n",
    "        # Define the main neural network\n",
    "        self.dense1 = Dense(32, activation='relu', input_dim = input_dim)\n",
    "        self.dropout1 = Dropout(0.3)  # Added Dropout layer\n",
    "        self.dense2 = Dense(16, activation='relu')\n",
    "        self.output_layer = Dense(1, activation='sigmoid')  # Binary classification\n",
    "    \n",
    "        \n",
    "        # Metrics and optimizer for Main Model\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(name=\"loss\")\n",
    "        self.optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.main_acc_metric = keras.metrics.BinaryAccuracy(name=\"accuracy\")\n",
    "\n",
    "        # Adversarial model (Gradient Boosted Trees)\n",
    "        self.adversarial_model = tfdf.keras.GradientBoostedTreesModel(task = tfdf.keras.Task.CLASSIFICATION)\n",
    "\n",
    "    def call(self, inputs, train = False):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout1(x, training = train)\n",
    "        x = self.dense2(x)\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "   \n",
    "    def fit(self, data):\n",
    "\n",
    "        # Number of Batches\n",
    "        num_batches = len(data)\n",
    "       \n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            # Epoch Progress Tracking\n",
    "            start_time = time.time()\n",
    "            print(f\"\\nEpoch {epoch + 1}/{self.epochs}\")\n",
    "            progbar = keras.utils.Progbar(target = num_batches)\n",
    "\n",
    "            # Track epoch loss\n",
    "            epoch_loss = 0\n",
    "\n",
    "            # Adversarial Model is Trained at every K Epochs\n",
    "            if epoch % self.GBT_retrain == 0:\n",
    "                y_preds = []\n",
    "                z_labels = []\n",
    "              \n",
    "\n",
    "                # Get Predictions For Most Recent Updated Main Model\n",
    "                for step, (X_batch_train, z_batch_train, _) in enumerate(data):\n",
    "                    y_preds.append(self(X_batch_train, train=False).numpy())  # Convert to NumPy for storage\n",
    "                    z_labels.append(z_batch_train.numpy())\n",
    "                   \n",
    "\n",
    "                # Convert stored batches to full arrays\n",
    "                y_preds = np.vstack(y_preds)  # Stack all predictions\n",
    "                z_labels = np.vstack(z_labels)  # Stack all sensitive features\n",
    "\n",
    "                # Train the adversarial model on predictions vs sensitive attribute\n",
    "                self.adversarial_model.fit(x=y_preds, y=z_labels)\n",
    "\n",
    "                # Compute Adversarial Model Loss\n",
    "                adversarial_model_loss  = self.adversarial_model.make_inspector().evaluation()[2]\n",
    "\n",
    "           \n",
    "            for step, (X_batch_train,_, y_batch_train) in enumerate(data):\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Forward pass\n",
    "                    y_pred = self(X_batch_train, train=True)\n",
    "\n",
    "                    # Compute Main Model Loss\n",
    "                    main_model_loss = self.loss_fn(y_batch_train, y_pred)\n",
    "\n",
    "                    # Compute Combined Loss\n",
    "                    combined_loss = main_model_loss + (main_model_loss / adversarial_model_loss + 1e-7) - (self.lambda_tradeoff * adversarial_model_loss)\n",
    "\n",
    "                # Compute gradients\n",
    "                gradients = tape.gradient(combined_loss, self.trainable_weights)\n",
    "\n",
    "                # Update weights\n",
    "                self.optimizer.apply_gradients(list(zip(gradients, self.trainable_weights)))\n",
    "\n",
    "          \n",
    "                 # Update training metric.\n",
    "                self.main_acc_metric.update_state(y_batch_train, y_pred)\n",
    "\n",
    "                # Track loss for epoch summary\n",
    "                epoch_loss += combined_loss.numpy()\n",
    "\n",
    "\n",
    "            # Update Progress Bar per batch\n",
    "            progbar.update(step + 1, values=[(\"loss\", float(combined_loss)), (\"accuracy\", float(self.main_acc_metric.result()))])\n",
    "             \n",
    "                    \n",
    "        # Final calculations per epoch\n",
    "        elapsed_time = time.time() - start_time\n",
    "        time_per_step = elapsed_time / num_batches * 1e6  # Convert to microseconds\n",
    "        final_accuracy = self.main_acc_metric.result().numpy()\n",
    "        final_loss = epoch_loss / num_batches\n",
    "\n",
    "        # Print final epoch stats\n",
    "        print(f\"\\n{num_batches}/{num_batches} - {int(elapsed_time)}s {int(time_per_step)}us/step - accuracy: {final_accuracy:.4f} - loss: {final_loss:.4f}\")\n",
    "\n",
    "        # Reset Accuracy for Next Epoch\n",
    "        self.main_acc_metric.reset_state()\n",
    "\n",
    "    def predict(self, X_input, threshold = None, raw_probabilities = None):\n",
    "\n",
    "    \n",
    "        if threshold is None:\n",
    "            threshold = 0.11\n",
    "\n",
    "        if raw_probabilities is None:\n",
    "            raw_probabilities = False\n",
    "\n",
    "        pred_proba = super().predict(X_input)\n",
    "\n",
    "        zpred_proba = self.adversarial_model.predict(pred_proba)\n",
    "\n",
    "        if raw_probabilities == True:\n",
    "\n",
    "            return pred_proba, zpred_proba\n",
    "        \n",
    "        else:\n",
    "             \n",
    "            binary_preds =  (pred_proba >= threshold).astype(int)\n",
    "            binary_zpreds = (zpred_proba >= threshold).astype(int)\n",
    "\n",
    "            return binary_preds, binary_zpreds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpwgcf5jdu as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsilva/DSC-180-Capstone/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-02-01 17:08:22.449081: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:22.449143: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:22.449165: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    }
   ],
   "source": [
    "model = AdversarialModel(41,'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.110624. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.099942\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458503.258878    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458503.258905    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458503.258912    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458503.258952    3538 kernel.cc:401] Number of batches: 32\n",
      "I0000 00:00:1738458503.258958    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458503.258977    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.661298 min:0.471423 max:0.822038 sd:0.0548077\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458503.258989    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:08:23.259120: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:23.259192: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:23.259215: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458503.259271    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458503.259339    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458503.259639   32395 kernel.cc:895] Train model\n",
      "2025-02-01 17:08:23.259699: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:08:23.259762: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:08:23.259923: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:08:23.262976: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:1.355501 train-accuracy:0.572048 valid-loss:1.376690 valid-accuracy:0.454545\n",
      "2025-02-01 17:08:23.265083: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1605] \tnum-trees:2 train-loss:1.331779 train-accuracy:0.611051 valid-loss:1.368132 valid-accuracy:0.428571\n",
      "I0000 00:00:1738458503.341997   32395 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:08:23.342038: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 41\n",
      "2025-02-01 17:08:23.345098: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:08:23.345205: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458503.345880   32395 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458503.348187   32395 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458503.349340    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:08:23.352918: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458503.357070    3538 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "I0000 00:00:1738458503.357132    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:08:23.357141: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.0384 - accuracy: 0.5150\n",
      "\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0159 - accuracy: 0.5090\n",
      "\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0349 - accuracy: 0.5057\n",
      "\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0834 - accuracy: 0.5185\n",
      "\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1251 - accuracy: 0.5240\n",
      "\n",
      "Epoch 6/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037287. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024811\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458510.248185    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458510.248212    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458510.248220    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458510.248265    3538 kernel.cc:401] Number of batches: 64\n",
      "I0000 00:00:1738458510.248270    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458510.248292    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.499749 min:0.368691 max:0.621243 sd:0.028885\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458510.248304    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:08:30.248460: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:30.248530: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:30.248551: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458510.248593    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458510.248659    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458510.248979     550 kernel.cc:895] Train model\n",
      "2025-02-01 17:08:30.249038: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:08:30.249099: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:08:30.249267: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:08:30.250135: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #41\n",
      "I0000 00:00:1738458510.258477     550 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "I0000 00:00:1738458510.258557     550 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:08:30.258605: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 175.7us\n",
      "I0000 00:00:1738458510.260821     550 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:08:30.260856: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 42\n",
      "2025-02-01 17:08:30.263349: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:08:30.263439: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458510.263815     550 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458510.264867     550 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458510.265282    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:08:30.267915: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:08:30.271924: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 1.0532 - accuracy: 0.5265\n",
      "\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0611 - accuracy: 0.5309\n",
      "\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1696 - accuracy: 0.5322\n",
      "\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9757 - accuracy: 0.5368\n",
      "\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0577 - accuracy: 0.5415\n",
      "\n",
      "Epoch 11/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037487. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024668\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458517.117529    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458517.117555    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458517.117564    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458517.117607    3538 kernel.cc:401] Number of batches: 96\n",
      "I0000 00:00:1738458517.117612    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458517.117634    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.488873 min:0.307514 max:0.675645 sd:0.0446308\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458517.117644    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:08:37.117795: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:37.117866: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:37.117889: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458517.117933    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458517.117995    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458517.118257     728 kernel.cc:895] Train model\n",
      "2025-02-01 17:08:37.118316: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:08:37.118374: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:08:37.118534: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:08:37.119531: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #42\n",
      "2025-02-01 17:08:37.128177: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 191.4us\n",
      "I0000 00:00:1738458517.130429     728 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:08:37.130456: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 43\n",
      "2025-02-01 17:08:37.132868: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:08:37.132964: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458517.133258     728 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458517.134211     728 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458517.134640    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:08:37.137133: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458517.141112    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:08:37.141131: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 1.1061 - accuracy: 0.5454\n",
      "\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9559 - accuracy: 0.5496\n",
      "\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.2129 - accuracy: 0.5512\n",
      "\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1414 - accuracy: 0.5547\n",
      "\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1337 - accuracy: 0.5569\n",
      "\n",
      "Epoch 16/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.040154. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027718\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458524.085383    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458524.085424    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458524.085434    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458524.085487    3538 kernel.cc:401] Number of batches: 128\n",
      "I0000 00:00:1738458524.085494    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458524.085519    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.470944 min:0.254457 max:0.654299 sd:0.0489129\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458524.085532    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:08:44.085716: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:44.085793: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:44.085819: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458524.085874    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458524.085947    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458524.086233     907 kernel.cc:895] Train model\n",
      "2025-02-01 17:08:44.086290: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:08:44.086337: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:08:44.086481: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:08:44.087562: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #43\n",
      "I0000 00:00:1738458524.096864     907 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:08:44.096954: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 279us\n",
      "I0000 00:00:1738458524.099195     907 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:08:44.099229: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 44\n",
      "2025-02-01 17:08:44.101946: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 41\n",
      "2025-02-01 17:08:44.102928: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:08:44.103013: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458524.103329     907 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458524.104386     907 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458524.104812    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:08:44.107426: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:08:44.111903: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 1.0355 - accuracy: 0.5589\n",
      "\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0067 - accuracy: 0.5619\n",
      "\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9852 - accuracy: 0.5633\n",
      "\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1657 - accuracy: 0.5642\n",
      "\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9983 - accuracy: 0.5663\n",
      "\n",
      "Epoch 21/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.036563. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028005\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458530.995621    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458530.995649    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458530.995657    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458530.995702    3538 kernel.cc:401] Number of batches: 160\n",
      "I0000 00:00:1738458530.995707    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458530.995728    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.505591 min:0.184786 max:0.799566 sd:0.0865626\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458530.995740    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:08:50.995904: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:50.995974: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:50.995995: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458530.996037    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458530.996101    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458530.996385    1091 kernel.cc:895] Train model\n",
      "2025-02-01 17:08:50.996445: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:08:50.996495: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:08:50.996640: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:08:50.997794: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #44\n",
      "2025-02-01 17:08:51.007863: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 316.5us\n",
      "I0000 00:00:1738458531.010247    1091 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:08:51.010289: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 45\n",
      "2025-02-01 17:08:51.012970: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 42\n",
      "2025-02-01 17:08:51.013981: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:08:51.014074: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458531.014402    1091 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458531.015554    1091 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458531.015975    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:08:51.018552: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458531.022530    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:08:51.022549: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.8199 - accuracy: 0.5683\n",
      "\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9887 - accuracy: 0.5703\n",
      "\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9792 - accuracy: 0.5727\n",
      "\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.2521 - accuracy: 0.5749\n",
      "\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7218 - accuracy: 0.5766\n",
      "\n",
      "Epoch 26/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037083. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028136\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458537.975414    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458537.975443    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458537.975453    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458537.975518    3538 kernel.cc:401] Number of batches: 192\n",
      "I0000 00:00:1738458537.975526    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458537.975556    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.486082 min:0.132005 max:0.824376 sd:0.1026\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458537.975573    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:08:57.975819: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:57.975925: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:08:57.975950: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458537.976006    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458537.976100    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458537.976804    1271 kernel.cc:895] Train model\n",
      "2025-02-01 17:08:57.976872: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:08:57.976935: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:08:57.977111: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:08:57.978300: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #45\n",
      "I0000 00:00:1738458537.987827    1271 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:08:57.987937: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 267.4us\n",
      "I0000 00:00:1738458537.990126    1271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:08:57.990168: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 46\n",
      "2025-02-01 17:08:57.992837: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 43\n",
      "2025-02-01 17:08:57.993824: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:08:57.993920: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458537.994243    1271 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458537.995321    1271 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458537.995768    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:08:57.998400: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458538.002330    3538 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "2025-02-01 17:08:58.002386: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.9389 - accuracy: 0.5793\n",
      "\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8470 - accuracy: 0.5811\n",
      "\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9548 - accuracy: 0.5835\n",
      "\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1183 - accuracy: 0.5857\n",
      "\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.0382 - accuracy: 0.5876\n",
      "\n",
      "Epoch 31/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.036636. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029044\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458544.920372    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458544.920399    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458544.920407    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458544.920456    3538 kernel.cc:401] Number of batches: 224\n",
      "I0000 00:00:1738458544.920461    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458544.920482    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.507531 min:0.122548 max:0.908583 sd:0.123894\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458544.920495    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:04.920666: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:04.920742: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:04.920765: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458544.920810    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458544.920872    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458544.921166    1451 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:04.921215: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:04.921264: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:04.921405: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:04.922618: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #46\n",
      "I0000 00:00:1738458544.932851    1451 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "2025-02-01 17:09:04.933129: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 368.9us\n",
      "I0000 00:00:1738458544.935478    1451 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:09:04.935507: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 47\n",
      "2025-02-01 17:09:04.938216: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 44\n",
      "2025-02-01 17:09:04.939328: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:09:04.939464: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458544.939844    1451 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458544.941076    1451 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458544.941534    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:04.944297: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458544.948360    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:04.948380: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.1184 - accuracy: 0.5897\n",
      "\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.8922 - accuracy: 0.5916\n",
      "\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8565 - accuracy: 0.5940\n",
      "\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.0406 - accuracy: 0.5960\n",
      "\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1140 - accuracy: 0.5979\n",
      "\n",
      "Epoch 36/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.050875. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028458\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458551.962583    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458551.962619    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458551.962628    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458551.962677    3538 kernel.cc:401] Number of batches: 256\n",
      "I0000 00:00:1738458551.962682    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458551.962706    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.520759 min:0.105122 max:0.954123 sd:0.151769\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458551.962718    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:11.962905: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:11.962978: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:11.963002: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458551.963052    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458551.963123    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458551.963363    1634 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:11.963426: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:11.963486: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:11.963659: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:11.964904: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #47\n",
      "I0000 00:00:1738458551.975082    1634 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:11.975257: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 360.1us\n",
      "I0000 00:00:1738458551.977516    1634 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:09:11.977555: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 48\n",
      "2025-02-01 17:09:11.980144: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 45\n",
      "2025-02-01 17:09:11.981143: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:09:11.981245: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458551.981580    1634 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458551.982660    1634 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458551.983087    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:11.985682: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:09:11.989875: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.8641 - accuracy: 0.6000\n",
      "\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7904 - accuracy: 0.6019\n",
      "\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0371 - accuracy: 0.6036\n",
      "\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8858 - accuracy: 0.6056\n",
      "\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0099 - accuracy: 0.6075\n",
      "\n",
      "Epoch 41/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037419. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027944\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458558.878984    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458558.879010    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458558.879019    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458558.879063    3538 kernel.cc:401] Number of batches: 288\n",
      "I0000 00:00:1738458558.879068    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458558.879089    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.51647 min:0.0655764 max:0.979489 sd:0.168318\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458558.879101    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:18.879258: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:18.879333: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:18.879356: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458558.879403    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458558.879462    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458558.879701    1814 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:18.879754: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:18.879804: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:18.879938: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:18.881113: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #48\n",
      "2025-02-01 17:09:18.891604: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 320.6us\n",
      "I0000 00:00:1738458558.893797    1814 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:09:18.893828: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 49\n",
      "2025-02-01 17:09:18.896404: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 46\n",
      "2025-02-01 17:09:18.897411: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:09:18.897503: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458558.897825    1814 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458558.898879    1814 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458558.899316    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:18.901846: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458558.905887    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:18.905909: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.6268 - accuracy: 0.6093\n",
      "\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.7588 - accuracy: 0.6118\n",
      "\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.2176 - accuracy: 0.6138\n",
      "\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.9744 - accuracy: 0.6159\n",
      "\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.7152 - accuracy: 0.6176\n",
      "\n",
      "Epoch 46/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.040641. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029726\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458566.024967    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458566.024996    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458566.025006    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458566.025055    3538 kernel.cc:401] Number of batches: 320\n",
      "I0000 00:00:1738458566.025060    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458566.025083    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.422282 min:0.0428402 max:0.976466 sd:0.176596\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458566.025095    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:26.025272: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:26.025333: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:26.025355: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458566.025401    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458566.025475    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458566.025880    1994 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:26.025930: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:26.025978: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:26.026118: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:26.027294: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #49\n",
      "I0000 00:00:1738458566.038222    1994 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:26.038364: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 324.3us\n",
      "I0000 00:00:1738458566.040733    1994 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:09:26.040771: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 50\n",
      "2025-02-01 17:09:26.043395: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 47\n",
      "2025-02-01 17:09:26.044438: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:09:26.044548: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458566.044910    1994 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458566.046048    1994 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458566.046466    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:26.049078: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:09:26.053353: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.6914 - accuracy: 0.6195\n",
      "\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.9634 - accuracy: 0.6212\n",
      "\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.3435 - accuracy: 0.6233\n",
      "\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.7637 - accuracy: 0.6252\n",
      "\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.3223 - accuracy: 0.6275\n",
      "\n",
      "Epoch 51/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037235. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029936\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458573.145732    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458573.145759    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458573.145768    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458573.145813    3538 kernel.cc:401] Number of batches: 352\n",
      "I0000 00:00:1738458573.145818    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458573.145839    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.557465 min:0.0484673 max:0.996414 sd:0.219122\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458573.145850    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:33.146002: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:33.146073: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:33.146097: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458573.146142    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458573.146202    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458573.146417    2177 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:33.146479: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:33.146552: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:33.146713: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:33.147918: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #50\n",
      "2025-02-01 17:09:33.159358: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 415.9us\n",
      "I0000 00:00:1738458573.161712    2177 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:09:33.161745: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 51\n",
      "2025-02-01 17:09:33.164657: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 48\n",
      "2025-02-01 17:09:33.165741: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:09:33.165838: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458573.166167    2177 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458573.167256    2177 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458573.167692    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:33.170450: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458573.174528    3538 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "I0000 00:00:1738458573.174588    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:33.174597: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 1.3150 - accuracy: 0.6292\n",
      "\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6320 - accuracy: 0.6307\n",
      "\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8108 - accuracy: 0.6322\n",
      "\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7135 - accuracy: 0.6341\n",
      "\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5177 - accuracy: 0.6359\n",
      "\n",
      "Epoch 56/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.050943. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.033064\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458580.104407    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458580.104451    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458580.104462    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458580.104513    3538 kernel.cc:401] Number of batches: 384\n",
      "I0000 00:00:1738458580.104518    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458580.104543    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.490575 min:0.0320306 max:0.992672 sd:0.223864\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458580.104555    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:40.104756: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:40.104829: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:40.104851: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458580.104901    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458580.104972    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458580.105443    2357 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:40.105503: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:40.105554: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:40.105704: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:40.106982: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #51\n",
      "I0000 00:00:1738458580.119342    2357 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "I0000 00:00:1738458580.119467    2357 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:40.119659: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 426.6us\n",
      "I0000 00:00:1738458580.122202    2357 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.32869\n",
      "2025-02-01 17:09:40.122234: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 52\n",
      "2025-02-01 17:09:40.125213: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 49\n",
      "2025-02-01 17:09:40.126305: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-02-01 17:09:40.126434: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:1.328688 valid-accuracy:0.610390\n",
      "I0000 00:00:1738458580.126813    2357 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458580.128048    2357 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458580.128473    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.32869\n",
      "\n",
      "Accuracy: 0.61039  CI95[W][0 1]\n",
      "ErrorRate: : 0.38961\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  12\n",
      "2  18  23\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:40.131521: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:09:40.136013: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.1237 - accuracy: 0.6377\n",
      "\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.3786 - accuracy: 0.6393\n",
      "\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.5891 - accuracy: 0.6406\n",
      "\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.8830 - accuracy: 0.6423\n",
      "\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.0430 - accuracy: 0.6438\n",
      "\n",
      "Epoch 61/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.038706. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.104150\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458587.172852    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458587.172878    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458587.172887    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458587.172935    3538 kernel.cc:401] Number of batches: 416\n",
      "I0000 00:00:1738458587.172941    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458587.172963    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.4855 min:0.0196847 max:0.99798 sd:0.24437\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458587.172975    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:47.173139: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:47.173211: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:47.173233: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458587.173276    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458587.173338    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458587.173591    2537 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:47.173646: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:47.173697: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:47.173835: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:47.175041: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #52\n",
      "2025-02-01 17:09:47.187081: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 401.5us\n",
      "2025-02-01 17:09:47.189665: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1605] \tnum-trees:54 train-loss:1.399250 train-accuracy:0.516793 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458587.252841    2537 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:09:47.252885: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 83\n",
      "2025-02-01 17:09:47.256642: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 50\n",
      "2025-02-01 17:09:47.257823: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:09:47.257917: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458587.258362    2537 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458587.260361    2537 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458587.260823    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:47.263470: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458587.275575    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:47.275613: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.1689 - accuracy: 0.6452\n",
      "\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7761 - accuracy: 0.6465\n",
      "\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.3116 - accuracy: 0.6477\n",
      "\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6534 - accuracy: 0.6493\n",
      "\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.8767 - accuracy: 0.6509\n",
      "\n",
      "Epoch 66/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037383. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.046847\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458594.334558    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458594.334587    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458594.334595    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458594.334641    3538 kernel.cc:401] Number of batches: 448\n",
      "I0000 00:00:1738458594.334646    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458594.334668    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.480124 min:0.0141094 max:0.997905 sd:0.251572\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458594.334680    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:09:54.334849: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:54.334922: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:09:54.334947: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458594.334995    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458594.335063    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458594.335518    3207 kernel.cc:895] Train model\n",
      "2025-02-01 17:09:54.335583: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:09:54.335645: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:09:54.335826: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:09:54.337090: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #83\n",
      "I0000 00:00:1738458594.355627    3207 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:09:54.355967: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 685.5us\n",
      "I0000 00:00:1738458594.358467    3207 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:09:54.358493: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 84\n",
      "2025-02-01 17:09:54.361621: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 51\n",
      "2025-02-01 17:09:54.362643: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:09:54.362728: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458594.363130    3207 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458594.364681    3207 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458594.365143    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:09:54.368218: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:09:54.380163: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.8884 - accuracy: 0.6525\n",
      "\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4558 - accuracy: 0.6538\n",
      "\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.9571 - accuracy: 0.6553\n",
      "\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5737 - accuracy: 0.6567\n",
      "\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1192 - accuracy: 0.6582\n",
      "\n",
      "Epoch 71/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037626. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.046306\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458601.311322    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458601.311349    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458601.311358    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458601.311402    3538 kernel.cc:401] Number of batches: 480\n",
      "I0000 00:00:1738458601.311408    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458601.311430    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.47278 min:0.00799302 max:0.998468 sd:0.261573\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458601.311442    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:10:01.311595: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:01.311667: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:01.311688: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458601.311732    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458601.311792    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458601.312087    3387 kernel.cc:895] Train model\n",
      "2025-02-01 17:10:01.312139: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:10:01.312199: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:10:01.312359: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:10:01.313519: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #84\n",
      "2025-02-01 17:10:01.331950: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 681.7us\n",
      "I0000 00:00:1738458601.334310    3387 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:10:01.334346: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 85\n",
      "2025-02-01 17:10:01.337738: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 52\n",
      "2025-02-01 17:10:01.338854: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:10:01.338955: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458601.339359    3387 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458601.340853    3387 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458601.341294    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:10:01.344186: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458601.356253    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:10:01.356297: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.5137 - accuracy: 0.6595\n",
      "\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9340 - accuracy: 0.6606\n",
      "\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9147 - accuracy: 0.6621\n",
      "\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.1171 - accuracy: 0.6636\n",
      "\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6971 - accuracy: 0.6650\n",
      "\n",
      "Epoch 76/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.042888. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.046706\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458608.306276    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458608.306304    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458608.306312    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458608.306356    3538 kernel.cc:401] Number of batches: 512\n",
      "I0000 00:00:1738458608.306361    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458608.306384    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.478603 min:0.00924196 max:0.999422 sd:0.276687\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458608.306395    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:10:08.306571: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:08.306644: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:08.306668: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458608.306718    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458608.306785    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458608.307016    3642 kernel.cc:895] Train model\n",
      "2025-02-01 17:10:08.307078: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:10:08.307137: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:10:08.307299: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:10:08.308495: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #85\n",
      "I0000 00:00:1738458608.326932    3642 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:10:08.327297: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 666us\n",
      "I0000 00:00:1738458608.329564    3642 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:10:08.329591: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 86\n",
      "2025-02-01 17:10:08.332800: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 83\n",
      "2025-02-01 17:10:08.333853: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:10:08.333951: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458608.334370    3642 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458608.335939    3642 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458608.336386    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:10:08.339272: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458608.351430    3538 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "2025-02-01 17:10:08.351650: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.8327 - accuracy: 0.6663\n",
      "\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.5018 - accuracy: 0.6674\n",
      "\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7576 - accuracy: 0.6690\n",
      "\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.5329 - accuracy: 0.6704\n",
      "\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6594 - accuracy: 0.6718\n",
      "\n",
      "Epoch 81/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.036400. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.046635\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458615.345212    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458615.345238    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458615.345246    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458615.345289    3538 kernel.cc:401] Number of batches: 544\n",
      "I0000 00:00:1738458615.345294    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458615.345315    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.480642 min:0.00586969 max:0.999595 sd:0.282042\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458615.345327    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:10:15.345487: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:15.345574: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:15.345598: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458615.345646    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458615.345715    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458615.346117    3827 kernel.cc:895] Train model\n",
      "2025-02-01 17:10:15.346185: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:10:15.346248: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:10:15.346418: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:10:15.347720: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #86\n",
      "I0000 00:00:1738458615.366328    3827 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "2025-02-01 17:10:15.366863: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 686.5us\n",
      "I0000 00:00:1738458615.369139    3827 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:10:15.369162: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 87\n",
      "2025-02-01 17:10:15.372024: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 84\n",
      "2025-02-01 17:10:15.373009: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:10:15.373103: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458615.373490    3827 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458615.374968    3827 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458615.375415    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:10:15.378173: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458615.390491    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:10:15.390534: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.3620 - accuracy: 0.6732\n",
      "\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6333 - accuracy: 0.6745\n",
      "\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.5914 - accuracy: 0.6756\n",
      "\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.3108 - accuracy: 0.6768\n",
      "\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5002 - accuracy: 0.6780\n",
      "\n",
      "Epoch 86/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.037099. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.047399\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458622.476745    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458622.476772    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458622.476780    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458622.476824    3538 kernel.cc:401] Number of batches: 576\n",
      "I0000 00:00:1738458622.476829    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458622.476850    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.51066 min:0.00435838 max:0.999832 sd:0.290794\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458622.476861    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:10:22.477016: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:22.477089: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:22.477110: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458622.477152    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458622.477212    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458622.477458    4007 kernel.cc:895] Train model\n",
      "2025-02-01 17:10:22.477520: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:10:22.477578: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:10:22.477723: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:10:22.479007: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #87\n",
      "I0000 00:00:1738458622.497829    4007 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:10:22.498238: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 739.3us\n",
      "I0000 00:00:1738458622.500637    4007 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:10:22.500665: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 88\n",
      "2025-02-01 17:10:22.504293: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 85\n",
      "2025-02-01 17:10:22.505419: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:10:22.505512: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458622.505918    4007 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458622.507515    4007 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458622.507940    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:10:22.510713: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:10:22.522799: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.8791 - accuracy: 0.6793\n",
      "\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.2565 - accuracy: 0.6805\n",
      "\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6509 - accuracy: 0.6816\n",
      "\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.3562 - accuracy: 0.6828\n",
      "\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4725 - accuracy: 0.6842\n",
      "\n",
      "Epoch 91/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.036383. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.048163\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458629.467137    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458629.467164    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458629.467176    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458629.467226    3538 kernel.cc:401] Number of batches: 608\n",
      "I0000 00:00:1738458629.467231    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458629.467252    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.47321 min:0.00167578 max:0.999837 sd:0.30366\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458629.467264    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:10:29.467414: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:29.467485: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:29.467508: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458629.467553    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458629.467612    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458629.467851    4187 kernel.cc:895] Train model\n",
      "2025-02-01 17:10:29.467910: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:10:29.467970: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:10:29.468132: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:10:29.469312: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #88\n",
      "2025-02-01 17:10:29.488683: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 698.7us\n",
      "I0000 00:00:1738458629.491299    4187 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.3209\n",
      "2025-02-01 17:10:29.491329: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 89\n",
      "2025-02-01 17:10:29.495105: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 86\n",
      "2025-02-01 17:10:29.496237: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 54 tree(s) i.e. 54  iteration(s).\n",
      "2025-02-01 17:10:29.496375: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:54 valid-loss:1.320902 valid-accuracy:0.597403\n",
      "I0000 00:00:1738458629.496860    4187 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458629.498705    4187 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458629.499155    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.3209\n",
      "\n",
      "Accuracy: 0.597403  CI95[W][0 1]\n",
      "ErrorRate: : 0.402597\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  24  20\n",
      "2  11  22\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:10:29.501922: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458629.513912    3538 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:10:29.513957: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.9997 - accuracy: 0.6853\n",
      "\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6616 - accuracy: 0.6862\n",
      "\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4771 - accuracy: 0.6873\n",
      "\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8254 - accuracy: 0.6886\n",
      "\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.5030 - accuracy: 0.6896\n",
      "\n",
      "Epoch 96/100\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.042272. Found 1000 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.166939\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738458636.512091    3538 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1738458636.512118    3538 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1738458636.512127    3538 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1738458636.512173    3538 kernel.cc:401] Number of batches: 640\n",
      "I0000 00:00:1738458636.512178    3538 kernel.cc:402] Number of examples: 1000\n",
      "I0000 00:00:1738458636.512202    3538 kernel.cc:802] Training dataset:\n",
      "Number of records: 1000\n",
      "Number of columns: 2\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 1 (50%)\n",
      "\tNUMERICAL: 1 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 1 (50%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 1 (50%)\n",
      "\t1: \"data:0\" NUMERICAL mean:0.472931 min:0.00181048 max:0.99993 sd:0.30397\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1738458636.512213    3538 kernel.cc:818] Configure learner\n",
      "2025-02-01 17:10:36.512425: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:36.512499: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-02-01 17:10:36.512522: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1738458636.512573    3538 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^data:0$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.1\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1738458636.512642    3538 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmpwgcf5jdu/working_cache\"\n",
      "num_threads: 16\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1738458636.513082    4370 kernel.cc:895] Train model\n",
      "2025-02-01 17:10:36.513145: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "2025-02-01 17:10:36.513204: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
      "2025-02-01 17:10:36.513368: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 923 examples used for training and 77 examples used for validation\n",
      "2025-02-01 17:10:36.514533: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:403] Resume the GBT training from snapshot #89\n",
      "I0000 00:00:1738458636.533659    4370 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-02-01 17:10:36.534048: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:435] Re-compute the prediction accumulators in 754.5us\n",
      "2025-02-01 17:10:36.536520: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1605] \tnum-trees:91 train-loss:1.425761 train-accuracy:0.527627 valid-loss:1.225102 valid-accuracy:0.675325\n",
      "I0000 00:00:1738458636.638682    4370 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.21561\n",
      "2025-02-01 17:10:36.638728: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1640] Create final snapshot of the model at iteration 145\n",
      "2025-02-01 17:10:36.643150: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:179] Remove snapshot of the model at iteration 87\n",
      "2025-02-01 17:10:36.644259: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 116 tree(s) i.e. 116  iteration(s).\n",
      "2025-02-01 17:10:36.644372: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:116 valid-loss:1.215606 valid-accuracy:0.727273\n",
      "I0000 00:00:1738458636.645039    4370 kernel.cc:926] Export model in log directory: /tmp/tmpwgcf5jdu with prefix 0d1d86e4d3df4ba8\n",
      "I0000 00:00:1738458636.647720    4370 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1738458636.648229    3538 abstract_model.cc:914] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.21561\n",
      "\n",
      "Accuracy: 0.727273  CI95[W][0 1]\n",
      "ErrorRate: : 0.272727\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  16\n",
      "2   5  15\n",
      "Total: 77\n",
      "\n",
      "\n",
      "2025-02-01 17:10:36.651214: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpwgcf5jdu/model/ with prefix 0d1d86e4d3df4ba8\n",
      "2025-02-01 17:10:36.677151: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.6503 - accuracy: 0.6906\n",
      "\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4331 - accuracy: 0.6917\n",
      "\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.8049 - accuracy: 0.6927\n",
      "\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7248 - accuracy: 0.6938\n",
      "\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.8216 - accuracy: 0.6949\n",
      "\n",
      "63/63 - 1s 21810us/step - accuracy: 0.6949 - loss: 0.6550\n"
     ]
    }
   ],
   "source": [
    "model.fit(shuffled_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Dummy set for Predict Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of rows and columns\n",
    "num_rows = 1000\n",
    "num_columns = 41\n",
    "\n",
    "# Generate random float data for 39 columns\n",
    "float_data = np.random.rand(num_rows, num_columns - 2)\n",
    "\n",
    "# Generate two binary columns\n",
    "binary_data = np.random.randint(0, 2, size=(num_rows, 2))\n",
    "\n",
    "# Combine into a single dataset\n",
    "data = np.hstack((float_data, binary_data))\n",
    "\n",
    "# Create column names\n",
    "column_names = [f\"feature_{i}\" for i in range(1, num_columns - 1)]\n",
    "column_names.append(\"Gender\")\n",
    "column_names.append(\"CHD\")\n",
    "\n",
    "# Create DataFrame\n",
    "df_predict = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.762664</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>0.784587</td>\n",
       "      <td>0.356771</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.497898</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.936143</td>\n",
       "      <td>0.489978</td>\n",
       "      <td>0.564812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403190</td>\n",
       "      <td>0.474390</td>\n",
       "      <td>0.497667</td>\n",
       "      <td>0.964042</td>\n",
       "      <td>0.672578</td>\n",
       "      <td>0.739626</td>\n",
       "      <td>0.633534</td>\n",
       "      <td>0.735760</td>\n",
       "      <td>0.127226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910774</td>\n",
       "      <td>0.566361</td>\n",
       "      <td>0.747105</td>\n",
       "      <td>0.025832</td>\n",
       "      <td>0.397878</td>\n",
       "      <td>0.476149</td>\n",
       "      <td>0.575739</td>\n",
       "      <td>0.326920</td>\n",
       "      <td>0.179086</td>\n",
       "      <td>0.149810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244063</td>\n",
       "      <td>0.824258</td>\n",
       "      <td>0.112698</td>\n",
       "      <td>0.260016</td>\n",
       "      <td>0.324769</td>\n",
       "      <td>0.226133</td>\n",
       "      <td>0.657886</td>\n",
       "      <td>0.571461</td>\n",
       "      <td>0.823201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995462</td>\n",
       "      <td>0.130282</td>\n",
       "      <td>0.655095</td>\n",
       "      <td>0.439705</td>\n",
       "      <td>0.732180</td>\n",
       "      <td>0.792697</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.918847</td>\n",
       "      <td>0.477402</td>\n",
       "      <td>0.784071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172986</td>\n",
       "      <td>0.657642</td>\n",
       "      <td>0.800218</td>\n",
       "      <td>0.668323</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.725450</td>\n",
       "      <td>0.693683</td>\n",
       "      <td>0.245175</td>\n",
       "      <td>0.890300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298222</td>\n",
       "      <td>0.794529</td>\n",
       "      <td>0.353065</td>\n",
       "      <td>0.637051</td>\n",
       "      <td>0.130808</td>\n",
       "      <td>0.984601</td>\n",
       "      <td>0.920892</td>\n",
       "      <td>0.167425</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0.090521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.790762</td>\n",
       "      <td>0.805609</td>\n",
       "      <td>0.484032</td>\n",
       "      <td>0.115285</td>\n",
       "      <td>0.612453</td>\n",
       "      <td>0.731313</td>\n",
       "      <td>0.953025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064734</td>\n",
       "      <td>0.612075</td>\n",
       "      <td>0.946083</td>\n",
       "      <td>0.724822</td>\n",
       "      <td>0.075990</td>\n",
       "      <td>0.373723</td>\n",
       "      <td>0.929611</td>\n",
       "      <td>0.171133</td>\n",
       "      <td>0.115018</td>\n",
       "      <td>0.420616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686042</td>\n",
       "      <td>0.821443</td>\n",
       "      <td>0.215723</td>\n",
       "      <td>0.528370</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>0.745641</td>\n",
       "      <td>0.889469</td>\n",
       "      <td>0.156075</td>\n",
       "      <td>0.644471</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.762664   0.108972   0.784587   0.356771   0.992820   0.497898   \n",
       "1   0.910774   0.566361   0.747105   0.025832   0.397878   0.476149   \n",
       "2   0.995462   0.130282   0.655095   0.439705   0.732180   0.792697   \n",
       "3   0.298222   0.794529   0.353065   0.637051   0.130808   0.984601   \n",
       "4   0.064734   0.612075   0.946083   0.724822   0.075990   0.373723   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_31  feature_32  \\\n",
       "0   0.002740   0.936143   0.489978    0.564812  ...    0.403190    0.474390   \n",
       "1   0.575739   0.326920   0.179086    0.149810  ...    0.244063    0.824258   \n",
       "2   0.527991   0.918847   0.477402    0.784071  ...    0.172986    0.657642   \n",
       "3   0.920892   0.167425   0.025938    0.090521  ...    0.608200    0.969789   \n",
       "4   0.929611   0.171133   0.115018    0.420616  ...    0.686042    0.821443   \n",
       "\n",
       "   feature_33  feature_34  feature_35  feature_36  feature_37  feature_38  \\\n",
       "0    0.497667    0.964042    0.672578    0.739626    0.633534    0.735760   \n",
       "1    0.112698    0.260016    0.324769    0.226133    0.657886    0.571461   \n",
       "2    0.800218    0.668323    0.913286    0.725450    0.693683    0.245175   \n",
       "3    0.790762    0.805609    0.484032    0.115285    0.612453    0.731313   \n",
       "4    0.215723    0.528370    0.043151    0.745641    0.889469    0.156075   \n",
       "\n",
       "   feature_39  Gender  \n",
       "0    0.127226     0.0  \n",
       "1    0.823201     1.0  \n",
       "2    0.890300     1.0  \n",
       "3    0.953025     1.0  \n",
       "4    0.644471     1.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = df_predict.drop([\"CHD\"], axis = 1)\n",
    "y_val = df.CHD\n",
    "x_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      0.0\n",
       "      ... \n",
       "995    0.0\n",
       "996    0.0\n",
       "997    1.0\n",
       "998    0.0\n",
       "999    0.0\n",
       "Name: CHD, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "32/32 [==============================] - 0s 648us/step\n"
     ]
    }
   ],
   "source": [
    "y_preds, zpreds = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer\n",
    "    loss='binary_crossentropy', # Binary Crossentropy loss\n",
    "    metrics=['accuracy']  # Track accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.9963  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9922277331352234, 0.0, 0.0]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.9963 \n",
      "[0.9922277331352234, 0.0, 0.0]\n",
      "Loss =  0.9922277331352234\n",
      "Accuracy =  0.0\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_val, y_val)\n",
    "print(loss_and_metrics)\n",
    "print('Loss = ',loss_and_metrics[0])\n",
    "print('Accuracy = ',loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.5009999871253967>}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
